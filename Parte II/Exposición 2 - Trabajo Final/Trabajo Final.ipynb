{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c6ed2b",
   "metadata": {},
   "source": [
    "# Redes Neuronales Estadísticamente Informadas\n",
    "\n",
    "![uami](./figuras/uami.png)\n",
    "\n",
    "**Maestría en Matemáticas Aplicadas**\n",
    "\n",
    "Alan Badillo Salas (cbi2242800355@xanum.uam.mx)\n",
    "\n",
    "> Taller de Modelado II\n",
    "> \n",
    "> Parte II (2137080)\n",
    "> \n",
    "> **Trabajo Final**\n",
    "> \n",
    "> *Trimestre: 25-P*\n",
    ">\n",
    "> Profesor: Dr. Joaquín Delgado Fernández"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a094f",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "La motivación sobre este tema es brindarle a las redes neuronales información estadística que acelere su entrenamiento y mejore las predicciones. Por ejemplo, aumentando la dimensión de los datos mediante información estadística o aplicando técnicas estadísticas para sintentizar los datos de una manera más coherente que permita que las redes neuronales profundas puedan alcanzar mejores resultados.\n",
    "\n",
    "> ¿Qué son las Redes Neuronales Estadísticamente Informadas?\n",
    "\n",
    "Son modelos de *deep learning* que incorporan principios, estructuras o transformaciones estadísticas explícitamente en la arquitectura, el preprocesamiento, o la interpretación de los datos.\n",
    "\n",
    "Se busca evitar supuestos ingenuos como la normalidad multivariada, o la linealidad simple, integrando herramientas estadísticas más robustas o estructuras informadas por la teoría del dominio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c85cc",
   "metadata": {},
   "source": [
    "# Avances relevantes y áreas de exploración"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5571f",
   "metadata": {},
   "source": [
    "## 1. Aumento de Dimensionalidad con Variables Derivadas Estadísticamente\n",
    "\n",
    "> ¿Qué es?\n",
    "\n",
    "Agregar variables cuadráticas, interacciones, polinomios, estadísticas resumen, componentes principales, o funciones kernel antes de entrenar redes.\n",
    "\n",
    "> Ejemplos:\n",
    "\n",
    "Método | Descripción\n",
    "--- | ---\n",
    "**Polynomial Networks** | Redes que reciben no solo las variables originales sino también sus combinaciones polinomiales.\n",
    "**Deep Feature Synthesis (AutoML tools como Featuretools)** | Generan automáticamente interacciones y estadísticas cruzadas.\n",
    "**Higher-Order Neural Units (HONUs)** | Redes con nodos que modelan interacciones cuadráticas o cúbicas directamente.\n",
    "**Functional ANOVA Embedding** | Usa el análisis de varianza funcional para definir interacciones significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f2831",
   "metadata": {},
   "source": [
    "## 2. Espacios Latentes con Significado Estadístico\n",
    "\n",
    "> ¿Qué es?\n",
    "\n",
    "Transformar las variables de entrada a espacios donde los datos están mejor distribuidos sin imponer normalidad (como PCA lo hace bajo varianzas)\n",
    "\n",
    "> Ejemplos:\n",
    "\n",
    "Método | Descripción\n",
    "--- | ---\n",
    "**Normalizing Flows** | Aprenden una transformación invertible que convierte la distribución original a una distribución simple (como la normal), pero sin perder información.\n",
    "**Variational Autoencoders (VAEs)** | Encoders con prior no normal o basados en copulas.\n",
    "**Copula-based Neural Networks** | Modelan explícitamente las dependencias entre variables sin asumir su distribución marginal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31496bae",
   "metadata": {},
   "source": [
    "## 3. Normalización Informada (Statistical Normalization Layers)\n",
    "\n",
    "> ¿Qué es?\n",
    "\n",
    "Son transformaciones que se pueden aplicar en lugar de `StandardScaler` o `BatchNorm`.\n",
    "\n",
    "> Ejemplos:\n",
    "\n",
    "Método | Descripción\n",
    "--- | ---\n",
    "**Quantile Normalization Layers** | Genera normalizaciones por agrupaciones cuantílicas\n",
    "**Rank Transformations** | Genera transformaciones basadas en ponderaciones\n",
    "**Group-wise normalization** | Separa por grupos estadísticos (por ejemplo, clases, regiones) antes de normalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95719d",
   "metadata": {},
   "source": [
    "> Bibliotecas útiles:\n",
    "\n",
    "* **torchsort**: para incorporar ordenamientos o cuantiles como capas diferenciables.\n",
    "* **normflows, nflows**: para flujos normales en *PyTorch*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967927d",
   "metadata": {},
   "source": [
    "## 4. Modelos con Componentes Estadísticos Internos\n",
    "\n",
    "> ¿Qué es?\n",
    "\n",
    "Son modelos que pueden ajustar componentes internos mediante redes neuronales, por ejemplo:\n",
    "\n",
    "$$\n",
    "y \\approx f_1(x_1) + f_2(x_2) + f_{12}(x_1, x_2)\n",
    "$$\n",
    "\n",
    "donde $f_1, f_2, f_{12}$ son pequeñas redes neuronales.\n",
    "\n",
    "> Híbridos entre modelos estadísticos y redes neuronales:\n",
    "\n",
    "Modelo | Descripción\n",
    "--- | ---\n",
    "**GLM-Nets** | Redes que incorporan partes de modelos lineales generalizados.\n",
    "**Neural Additive Models (NAMs)** | Redes donde cada variable tiene su propia subred, manteniendo interpretabilidad tipo regresión aditiva.\n",
    "**Spline-based models** | Incorporan funciones splines dentro de la arquitectura (usado en medicina, bioestadística)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387fb2e7",
   "metadata": {},
   "source": [
    "## 5. Regularización basada en estadística\n",
    "\n",
    "> ¿Qué es?\n",
    "\n",
    "Usar la teoría estadística para regularizar modelos de *deep learning*.\n",
    "\n",
    "> Ejemplos:\n",
    "\n",
    "Método | Descripción\n",
    "--- | ---\n",
    "**Informative Priors** | Utiliza los priors informativos en redes bayesianas.\n",
    "**Dropout no uniforme** | Regularización informada por la varianza o la importancia estadística de las variables.\n",
    "**Sparse regression layers** | Funcina como LASSO o Ridge dentro de una red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94f149",
   "metadata": {},
   "source": [
    "## 6. Modelos Cuadráticos / Interacciones Explicitas\n",
    "\n",
    "> ¿Qué es?\n",
    "\n",
    "Son estructuras que permiten expresar:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1 x_2 + \\beta_{13} x_1 x_3 + \\dots\n",
    "$$\n",
    "\n",
    "> Ejemplos:\n",
    "\n",
    "Modelo | Descripción\n",
    "--- | ---\n",
    "**Factorization Machines (FMs)** | Genera factorizaciones complejas\n",
    "**Field-aware FMs (FFMs)** | Modelos de factorización más avanzados\n",
    "**PolyNet**, **Deep Cross Networks** | Funciona como en los modelos de recomendación\n",
    "**Tensor Neural Networks** | Aprenden interacciones cruzadas de alto orden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e356ab9f",
   "metadata": {},
   "source": [
    "## 7. Modelos Deep + Estadísticos en Series de Tiempo\n",
    "\n",
    "> ¿Qué es?\n",
    "\n",
    "Son modelos que permiten usar información temporal para las predicciones (*forecasting*).\n",
    "\n",
    "> Ejemplos:\n",
    "\n",
    "Modelo | Descripción\n",
    "--- | ---\n",
    "**DeepAR** | Redes recurrentes con modelos probabilísticos por serie.\n",
    "**Deep State Space Models** | Combinación de redes con modelos espacio-estado estadísticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131e1365",
   "metadata": {},
   "source": [
    "# Referencias de interés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82175e0",
   "metadata": {},
   "source": [
    "> Artículos clave\n",
    "\n",
    "Título | Autores\n",
    "--- | ---\n",
    "**Neural Additive Models: Interpretable Machine Learning with Neural Nets** | Agarwal et al., 2021\n",
    "**Normalizing Flows for Probabilistic Modeling and Inference** | Papamakarios et al., 2021\n",
    "**Deep Factorization Machines for Knowledge Tracing** | Vie & Kashima, 2020\n",
    "**Deep Feature Synthesis: Towards Automating Data Science Endeavors** | Kanter & Veeramachaneni, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c954cd4",
   "metadata": {},
   "source": [
    "> Libros recomendados\n",
    "\n",
    "Título | Autor\n",
    "--- | ---\n",
    "**Deep Learning with PyTorch** | Manning Publications\n",
    "**Probabilistic Deep Learning** | Kevin Murphy\n",
    "**Elements of Statistical Learning** | Hastie, Tibshirani y Friedman"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
